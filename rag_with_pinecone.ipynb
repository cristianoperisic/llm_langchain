{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05dbcbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lw105\\OneDrive\\ë°”íƒ• í™”ë©´\\LangChain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# File: 4.rag_with_pinecone.ipynb\n",
    "# Purpose: ë¡œì»¬ í´ë”ì˜ ëª¨ë“  PDFë¥¼ ì½ì–´ Pineconeì— ì €ì¥í•˜ê³  í…ŒìŠ¤íŠ¸\n",
    "# =================================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e135935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# í‚¤ í™•ì¸\n",
    "if not os.getenv(\"OPENAI_API_KEY\") or not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    print(\"ğŸš¨ .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”! í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "# 2. ì„¤ì •\n",
    "INDEX_NAME = \"rm-project-index\"  # Pineconeì—ì„œ ë§Œë“  ì¸ë±ìŠ¤ ì´ë¦„ê³¼ ê°™ì•„ì•¼ í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633f147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ë°œê²¬ëœ PDF íŒŒì¼: ['googleê°œì¸ì •ë³´ì²˜ë¦¬ë°©ì¹¨.pdf', 'googleì„œë¹„ìŠ¤ì•½ê´€.pdf', 'ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ ì‘ì„±ì§€ì¹¨(2025.4.).pdf', 'ë„¤ì´ë²„.pdf', 'ë„·í”Œë¦­ìŠ¤.pdf', 'ì†Œë¹„ìë¶„ìŸí•´ê²°ê¸°ì¤€ ê°œì •ì•ˆ(2025).pdf', 'ì•½ê´€ì˜ ê·œì œì— ê´€í•œ ë²•ë¥ (ë²•ë¥ )(ì œ20239í˜¸)(20240807).pdf']\n",
      "   âœ… ë¡œë“œ ì„±ê³µ: googleê°œì¸ì •ë³´ì²˜ë¦¬ë°©ì¹¨.pdf\n",
      "   âœ… ë¡œë“œ ì„±ê³µ: googleì„œë¹„ìŠ¤ì•½ê´€.pdf\n",
      "   âœ… ë¡œë“œ ì„±ê³µ: ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ ì‘ì„±ì§€ì¹¨(2025.4.).pdf\n",
      "   âœ… ë¡œë“œ ì„±ê³µ: ë„¤ì´ë²„.pdf\n",
      "   âœ… ë¡œë“œ ì„±ê³µ: ë„·í”Œë¦­ìŠ¤.pdf\n",
      "   âœ… ë¡œë“œ ì„±ê³µ: ì†Œë¹„ìë¶„ìŸí•´ê²°ê¸°ì¤€ ê°œì •ì•ˆ(2025).pdf\n",
      "   âœ… ë¡œë“œ ì„±ê³µ: ì•½ê´€ì˜ ê·œì œì— ê´€í•œ ë²•ë¥ (ë²•ë¥ )(ì œ20239í˜¸)(20240807).pdf\n",
      "ğŸ“Š ì´ 536ê°œì˜ ì§€ì‹ ì²­í¬ ìƒì„±ë¨\n"
     ]
    }
   ],
   "source": [
    "# 3. í˜„ì¬ í´ë”ì˜ ëª¨ë“  PDF ì°¾ê¸°\n",
    "pdf_files = glob.glob(\"*.pdf\")\n",
    "print(f\"ğŸ“‚ ë°œê²¬ëœ PDF íŒŒì¼: {pdf_files}\")\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"ğŸš¨ í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.\")\n",
    "else:\n",
    "    # 4. ë¬¸ì„œ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "    documents = []\n",
    "\n",
    "    for file_path in pdf_files:\n",
    "        try:\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            docs = loader.load()\n",
    "\n",
    "            # ë©”íƒ€ë°ì´í„°ì— íŒŒì¼ëª…(ì¶œì²˜) ì¶”ê°€ -> ë‹µë³€í•  ë•Œ \"ì–´ëŠ ë¬¸ì„œì—ì„œ ë´¤ë‹¤\"ê³  ë§í•˜ê¸° ìœ„í•¨\n",
    "            for doc in docs:\n",
    "                doc.metadata[\"source\"] = file_path\n",
    "\n",
    "            documents.extend(docs)\n",
    "            print(f\"   âœ… ë¡œë“œ ì„±ê³µ: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ë¡œë“œ ì‹¤íŒ¨: {file_path} - {e}\")\n",
    "\n",
    "    if documents:\n",
    "        # ì²­í‚¹ (ë²•ë¥  ë¬¸ì„œëŠ” í˜¸í¡ì´ ê¸¸ì–´ì„œ 1000ì ë‹¨ìœ„ ì¶”ì²œ)\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000, chunk_overlap=200\n",
    "        )\n",
    "        texts = text_splitter.split_documents(documents)\n",
    "        print(f\"ğŸ“Š ì´ {len(texts)}ê°œì˜ ì§€ì‹ ì²­í¬ ìƒì„±ë¨\")\n",
    "\n",
    "        # 5. Pineconeì— ì—…ë¡œë“œ\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "\n",
    "        print(f\"ğŸš€ Pinecone Index '{INDEX_NAME}'ì— ì €ì¥ ì¤‘...\")\n",
    "        docsearch = PineconeVectorStore.from_documents(\n",
    "            texts, embeddings, index_name=INDEX_NAME\n",
    "        )\n",
    "        print(\"âœ… ì €ì¥ ì™„ë£Œ! ì ì‹œ ëŒ€ê¸°(3ì´ˆ)...\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        # 6. RAG í…ŒìŠ¤íŠ¸ (RM í˜ë¥´ì†Œë‚˜)\n",
    "        template = \"\"\"\n",
    "        ë‹¹ì‹ ì€ 'ë¶ˆê³µì • ì•½ê´€ ì‹¬ì‚¬ ì „ë¬¸ AI ë³€í˜¸ì‚¬ RM'ì…ë‹ˆë‹¤.\n",
    "        ë°ì´í„°ë² ì´ìŠ¤ì—ëŠ” [ë²•ì  ê¸°ì¤€]ê³¼ [ê¸°ì—… ì•½ê´€]ì´ ì„ì—¬ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "        [ì„ë¬´]\n",
    "        ë°˜ë“œì‹œ **[ë²•ì  ê¸°ì¤€ ë¬¸ì„œ]**ì˜ ë‚´ìš©ì„ ê·¼ê±°ë¡œ **[ê¸°ì—… ì•½ê´€]**ì´ ê³µì •í•œì§€ íŒê²°í•˜ì„¸ìš”.\n",
    "        \n",
    "        [ë‹µë³€ í˜•ì‹]\n",
    "        - ê²°ë¡ : (ê³µì •/ë¶ˆê³µì •)\n",
    "        - ê·¼ê±°: ë²•ë ¹ ë‚´ìš© ì¸ìš©\n",
    "        - ì¶œì²˜: **[ì¶œì²˜: íŒŒì¼ëª…]** í‘œê¸° í•„ìˆ˜\n",
    "\n",
    "        Context: {context}\n",
    "        Question: {question}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        PROMPT = PromptTemplate(\n",
    "            template=template, input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "        qa = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=docsearch.as_retriever(search_kwargs={\"k\": 5}),\n",
    "            chain_type_kwargs={\"prompt\": PROMPT},\n",
    "        )\n",
    "\n",
    "        # ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\n",
    "        query = \"ë„·í”Œë¦­ìŠ¤ ì•½ê´€ì´ë‘ ì†Œë¹„ìë¶„ìŸí•´ê²°ê¸°ì¤€ ë¹„êµí–ˆì„ ë•Œ í™˜ë¶ˆ ê·œì • ë¬¸ì œ ìˆì–´?\"\n",
    "        print(f\"\\nğŸ” Test Question: {query}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(qa.invoke({\"query\": query})[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
